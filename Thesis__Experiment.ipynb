{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis_ Experiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQazJJqdeJAFRcc5LTCawI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bfSfzBqGrCU"
      },
      "source": [
        "from node2vec import Node2Vec\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import networkx.algorithms.community as nx_com\n",
        "import networkx.algorithms.centrality as nx_cen\n",
        "import random \n",
        "import copy\n",
        "import math\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from random import uniform, seed\n",
        "import pandas as pd\n",
        "import time\n",
        "from collections import Counter\n",
        "from igraph import Graph  \n",
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "import itertools \n",
        "import heapq\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import genetic_algorithm\n",
        "import genetic_im_opt\n",
        "import celfpp\n",
        "import simulated_annealing\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sLO15QGHzNQ"
      },
      "source": [
        "Email_df = pd.read_csv('/content/email-Eu-core.txt.gz', compression='gzip', names=[\"source\", \"target\"], sep=' ', quotechar='\"', error_bad_lines=False)\n",
        "fb_df = pd.read_csv('/content/facebook_combined.txt.gz', compression='gzip', names=[\"source\", \"target\"], sep=' ', quotechar='\"', error_bad_lines=False)\n",
        "# twitter_df = pd.read_csv('/content/twitter_combined.txt.gz', compression='gzip', names=[\"source\", \"target\"], sep=' ', quotechar='\"', error_bad_lines=False)\n",
        "# txroad_df = pd.read_csv('/content/roadNet-TX.txt',sep='\\t',skiprows=(0,1,2,3),names=[\"source\", \"target\"],quotechar='\"',error_bad_lines=False)\n",
        "# wiki_df = pd.read_csv('/content/Wiki-Vote.txt', names=[\"source\", \"target\"], sep='/t', quotechar='\"', error_bad_lines=False)\n",
        "# Email Data to Graph\n",
        "Email_graph=Graph(directed=True)\n",
        "Email_graph.add_vertices(1005)\n",
        "Email_graph.add_edges(zip(Email_df[\"source\"], Email_df[\"target\"]))\n",
        "print(\"Number of vertices in the graph:\", Email_graph.vcount())\n",
        "print(\"Number of edges in the graph\",Email_graph.ecount())\n",
        "print(\"Is the graph directed:\", Email_graph.is_directed())\n",
        "print(\"Maximum degree in the graph:\", Email_graph.maxdegree())\n",
        "print('Graph Summary: ', Email_graph.summary())\n",
        "\n",
        "# Facebook Data to Graph\n",
        "fb_graph=Graph(directed=True)\n",
        "fb_graph.add_vertices(4039)\n",
        "fb_graph.add_edges(zip(fb_df[\"source\"], fb_df[\"target\"]))\n",
        "print(\"Number of vertices in the graph:\", fb_graph.vcount())\n",
        "print(\"Number of edges in the graph\",fb_graph.ecount())\n",
        "print(\"Is the graph directed:\", fb_graph.is_directed())\n",
        "print(\"Maximum degree in the graph:\", fb_graph.maxdegree())\n",
        "print('Graph Summary: ', fb_graph.summary())\n",
        "\n",
        "# # Twitter Data\n",
        "# twitter_graph=Graph(directed=True)\n",
        "# twitter_graph.add_vertices(81306)\n",
        "# # twitter_graph.add_edges(zip(twitter_df[\"source\"], twitter_df[\"target\"]))\n",
        "# print(\"Number of vertices in the graph:\", twitter_graph.vcount())\n",
        "# print(\"Number of edges in the graph\",twitter_graph.ecount())\n",
        "# print(\"Is the graph directed:\", twitter_graph.is_directed())\n",
        "# print(\"Maximum degree in the graph:\", twitter_graph.maxdegree())\n",
        "# print('Graph Summary: ', twitter_graph.summary())\n",
        "\n",
        "# # Text Road Network Data\n",
        "# txroad_graph=Graph(directed=True)\n",
        "# txroad_graph.add_vertices(1393361)\n",
        "# txroad_graph.add_edges(zip(txroad_df[\"source\"], txroad_df[\"target\"]))\n",
        "# print(\"Number of vertices in the graph:\", txroad_graph.vcount())\n",
        "# print(\"Number of edges in the graph\",txroad_graph.ecount())\n",
        "# print(\"Is the graph directed:\", txroad_graph.is_directed())\n",
        "# print(\"Maximum degree in the graph:\", txroad_graph.maxdegree())\n",
        "# print('Graph Summary: ', txroad_graph.summary())\n",
        "\n",
        "Emailx_graph = nx.from_pandas_edgelist(Email_df,'source','target')\n",
        "fbx_graph = nx.from_pandas_edgelist(fb_df,'source','target')\n",
        "nx.draw(Emailx_graph,pos=nx.spring_layout(Emailx_graph),with_labels=True)\n",
        "plt.show()\n",
        "nx.draw(fbx_graph,pos=nx.spring_layout(fbx_graph),with_labels=True)\n",
        "plt.show()\n",
        "Email_node_degree = Emailx_graph.degree()\n",
        "fb_node_degree = fbx_graph.degree()\n",
        "Email_n2v = Node2Vec(Emailx_graph, dimensions=2,walk_length=20,num_walks=10,seed=10,temp_folder='/content', workers=1)\n",
        "fb_n2v = Node2Vec(fbx_graph, dimensions=2,walk_length=40,num_walks=20,seed=10,temp_folder='/content', workers=1)\n",
        "# twitter_n2v = Node2Vec(twitterx_graph, dimensions=2,walk_length=60,num_walks=30,seed=10,temp_folder='/content', workers=1)\n",
        "# txroad_n2v = Node2Vec(txroadx_graph, dimensions=2,walk_length=80,num_walks=40,seed=10,temp_folder='/content', workers=1)\n",
        "Email_model = Email_n2v.fit(window=4,min_count=1,batch_words=2)\n",
        "fb_model = fb_n2v.fit(window=4,min_count=1,batch_words=2)\n",
        "# twitter_model = twitter_n2v.fit(window=4,min_count=1,batch_words=2)\n",
        "# txroad_model = txroad_n2v.fit(window=4,min_count=1,batch_words=2)\n",
        "Email_model.wv.save_word2vec_format('./Email_emb.csv')\n",
        "fb_model.wv.save_word2vec_format('./fb_emb.csv')\n",
        "# twitter_model.wv.save_word2vec_format('./twitter_emb.csv')\n",
        "# txroad_model.wv.save_word2vec_format('./txroad_emb.csv')\n",
        "Email_emb_df = pd.read_csv('/content/Email_emb.csv',sep=' ',skiprows=[0],header=None)\n",
        "Email_emb_df.columns = ['source','em1','em2']\n",
        "\n",
        "fb_emb_df = pd.read_csv('/content/fb_emb.csv',sep=' ',skiprows=[0],header=None)\n",
        "fb_emb_df.columns = ['source','em1','em2']\n",
        "# eu_df\n",
        "Email_temp_df = pd.merge(Email_df,Email_emb_df)\n",
        "Email_temp_df['degree'] =Email_temp_df['source'].map(Email_node_degree)\n",
        "\n",
        "fb_temp_df = pd.merge(fb_df,fb_emb_df)\n",
        "fb_temp_df['degree'] =fb_temp_df['source'].map(fb_node_degree)\n",
        "# temp_df\n",
        "silhoute_avg =[]\n",
        "n_cluster_range = range(40,50)\n",
        "for NUM_CLUSTERS in n_cluster_range:\n",
        "# NUM_CLUSTERS = 10\n",
        "\n",
        "  kmeans = KMeans(n_clusters=NUM_CLUSTERS)\n",
        "  kmeans.fit(temp_df)\n",
        "  cluster_labels = kmeans.labels_\n",
        "  # print(cluster_labels)\n",
        "  # print(np.unique(cluster_labels))\n",
        "  silhoute_avg.append(silhouette_score(temp_df,cluster_labels))\n",
        " \n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(n_cluster_range,silhoute_avg,'bx-')\n",
        "plt.xlabel('Values of K') \n",
        "plt.ylabel('Silhouette score') \n",
        "plt.title('Silhouette analysis For Optimal k')\n",
        "plt.show()\n",
        "\n",
        "Email_kmeans = KMeans(n_clusters=42)\n",
        "Email_kmeans.fit(Email_temp_df)\n",
        "labels = Email_kmeans.predict(Email_temp_df)\n",
        "Email_temp_df['cluster'] = labels\n",
        "Email_temp_df\n",
        "\n",
        "fb_kmeans = KMeans(n_clusters=80)\n",
        "fb_kmeans.fit(fb_temp_df)\n",
        "labels = fb_kmeans.predict(fb_temp_df)\n",
        "fb_temp_df['cluster'] = labels\n",
        "fb_temp_df\n",
        "\n",
        "Email_temp1 = Email_temp_df.groupby(by='cluster').agg('count').sort_values('source', ascending=False)\n",
        "fb_temp1 = fb_temp_df.groupby(by='cluster').agg('count').sort_values('source', ascending=False)\n",
        "Email_sig_clusters = list(Email_temp1[:30].index)\n",
        "fb_sig_clusters = list(fb_temp1[:60].index)\n",
        " \n",
        "Eamil_temp2 = Email_temp_df[Email_temp_df.cluster.isin(Email_sig_clusters)]\n",
        "fb_temp2 = fb_temp_df[fb_temp_df.cluster.isin(fb_sig_clusters)]\n",
        "fb_temp2.head(20)\n",
        "\n",
        "# Email EU Core Graph Greedy Celf++\n",
        "graph=Email_graph\n",
        "df = Eamil_temp2 \n",
        "# greedy_spreads1=[] \n",
        "# greedy_elapsed1=[]  \n",
        "# celf_elapsed1=[]\n",
        "# celf_spreads1=[] \n",
        "# celfpp_spreads1=[] \n",
        "# celfpp_elapsed1=[]\n",
        "simulated_annealing_spreads1=[] \n",
        "simulated_annealing_elapsed1=[]\n",
        "simulated_annealing_solution1=[] \n",
        "genetic_algorithm_spreads1=[] \n",
        "genetic_algorithm_elapsed1=[]\n",
        "genetic_algorithm_solution1=[]\n",
        "opt_genetic_algorithm_spreads1=[] \n",
        "opt_genetic_algorithm_elapsed1=[]\n",
        "opt_genetic_algorithm_solution1=[]\n",
        "\n",
        "lower_seed_size,higher_seed_size=50,200\n",
        "for i in tqdm(range(lower_seed_size,higher_seed_size,10)):\n",
        "    k = i\n",
        "    prob = 0.5\n",
        "    n_iters =200\n",
        "    generation_count=80\n",
        "    population_size=800\n",
        "   \n",
        "    # greedy_solution, greedy_spreads, greedy_elapsed = greedy_algorithm.algo(graph, k, prob, n_iters)\n",
        "    # celf_solution, celf_spreads, celf_elapsed = celf.algo(graph, k, prob, n_iters)\n",
        "    \n",
        "    # celfpp_solution, celfpp_spreads, celfpp_elapsed = celfpp.algo(graph, k, prob, n_iters)\n",
        "    \n",
        "    opt_genetic_algorithm_solution,opt_genetic_algorithm_spreads,opt_genetic_algorithm_elapsed=genetic_im_opt.algo(graph,df,generation_count,population_size,k)\n",
        "    genetic_algorithm_solution,genetic_algorithm_spreads,genetic_algorithm_elapsed=genetic_algorithm.algo(graph,generation_count,population_size,k)\n",
        "    simulated_annealing_solution,simulated_annealing_spreads,simulated_annealing_elapsed=simulated_annealing.algo(graph,k,prob,n_iters)\n",
        "\n",
        "    \n",
        "    \n",
        " \n",
        "    \n",
        "    # greedy_spreads1.append(greedy_spreads)\n",
        "    # greedy_elapsed1.append(greedy_elapsed)\n",
        "    \n",
        "    # celf_spreads1.append(celf_spreads) \n",
        "    # celf_elapsed1.append(celf_elapsed)\n",
        "    # celfpp_spreads1.append(celfpp_spreads) \n",
        "    # celfpp_elapsed1.append(celfpp_elapsed)\n",
        "    \n",
        "    simulated_annealing_spreads1.append(simulated_annealing_spreads) \n",
        "    simulated_annealing_elapsed1.append(simulated_annealing_elapsed)\n",
        "    simulated_annealing_solution1.append(simulated_annealing_solution)\n",
        "    genetic_algorithm_spreads1.append(genetic_algorithm_spreads) \n",
        "    genetic_algorithm_elapsed1.append(genetic_algorithm_elapsed)\n",
        "    genetic_algorithm_solution1.append(genetic_algorithm_solution)\n",
        "    opt_genetic_algorithm_spreads1.append(opt_genetic_algorithm_spreads) \n",
        "    opt_genetic_algorithm_elapsed1.append(opt_genetic_algorithm_elapsed)\n",
        "    opt_genetic_algorithm_solution1.append(opt_genetic_algorithm_solution)\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}