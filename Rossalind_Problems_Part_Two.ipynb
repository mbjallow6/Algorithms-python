{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMygtJ0/gHTGAbAQo5qmqTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbjallow6/Algorithms-python/blob/main/Rossalind_Problems_Part_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DwurSxeC6tbH",
        "outputId": "c9816fe3-b595-437d-d4ef-af61468f6732"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-124048a3-70cf-42c6-9635-388faf9572e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-124048a3-70cf-42c6-9635-388faf9572e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rosalind_pdpl.txt to rosalind_pdpl.txt\n"
          ]
        }
      ],
      "source": [
        "# import data from the computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind Cyclic Superstring from k-mers Solution"
      ],
      "metadata": {
        "id": "JkYAjRNxpH7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Cyclic Superstring from k-mers Solution (Corrected)\n",
        "\n",
        "This module reconstructs a minimal cyclic superstring from a set of k-mers\n",
        "forming a de Bruijn graph with exactly one simple cycle.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict, Set\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "class CyclicSuperstringReconstructor:\n",
        "    \"\"\"\n",
        "    A class to reconstruct a minimal cyclic superstring from k-mers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the reconstructor.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def build_de_bruijn_graph(self, kmers: List[str]) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Build the de Bruijn graph from k-mers.\n",
        "\n",
        "        Args:\n",
        "            kmers (List[str]): List of k-mers\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, List[str]]: Adjacency list\n",
        "        \"\"\"\n",
        "        adj = defaultdict(list)\n",
        "        for kmer in kmers:\n",
        "            prefix = kmer[:-1]\n",
        "            suffix = kmer[1:]\n",
        "            adj[prefix].append(suffix)\n",
        "        return adj\n",
        "\n",
        "    def find_eulerian_cycle(self, adj: Dict[str, List[str]]) -> List[str]:\n",
        "        graph = defaultdict(list)\n",
        "        for node, neighbors in adj.items():\n",
        "            graph[node] = list(neighbors)\n",
        "\n",
        "        # Total edges\n",
        "        total_edges = sum(len(graph[node]) for node in graph)\n",
        "\n",
        "        # Start from a node with outgoing edges\n",
        "        start = next((node for node in graph if graph[node]), None)\n",
        "        if not start:\n",
        "            return []\n",
        "\n",
        "        cycle = []\n",
        "        stack = [start]\n",
        "\n",
        "        while stack:\n",
        "            current = stack[-1]\n",
        "            if graph[current]:\n",
        "                stack.append(graph[current].pop())\n",
        "            else:\n",
        "                cycle.append(stack.pop())\n",
        "\n",
        "        cycle.reverse()\n",
        "\n",
        "        # Merge sub-cycles if remaining edges\n",
        "        while sum(len(graph[node]) for node in graph) > 0:\n",
        "            # Find node in cycle with remaining edges\n",
        "            for idx, node in enumerate(cycle):\n",
        "                if graph[node]:\n",
        "                    # Run sub-tour\n",
        "                    sub_stack = [node]\n",
        "                    sub_cycle = []\n",
        "                    while sub_stack:\n",
        "                        sub_current = sub_stack[-1]\n",
        "                        if graph[sub_current]:\n",
        "                            sub_stack.append(graph[sub_current].pop())\n",
        "                        else:\n",
        "                            sub_cycle.append(sub_stack.pop())\n",
        "                    sub_cycle.reverse()\n",
        "                    # Insert into main cycle\n",
        "                    cycle = cycle[:idx] + sub_cycle + cycle[idx + 1:]\n",
        "                    break\n",
        "            else:\n",
        "                raise ValueError(\"No node with remaining edges found in cycle\")\n",
        "\n",
        "        # Cycle length should be total_edges + 1\n",
        "        if len(cycle) != total_edges + 1:\n",
        "            raise ValueError(\"Cycle length incorrect\")\n",
        "\n",
        "        return cycle\n",
        "\n",
        "    def reconstruct_cyclic_superstring(self, kmers: List[str]) -> str:\n",
        "        if not kmers:\n",
        "            return \"\"\n",
        "\n",
        "        adj = self.build_de_bruijn_graph(kmers)\n",
        "        cycle = self.find_eulerian_cycle(adj)\n",
        "\n",
        "        m = len(kmers)\n",
        "        k = len(kmers[0]) if kmers else 0\n",
        "\n",
        "        if len(cycle) != m + 1:\n",
        "            raise ValueError(\"Eulerian cycle does not cover all k-mers\")\n",
        "\n",
        "        # Build full superstring\n",
        "        superstring = cycle[0]\n",
        "        for node in cycle[1:]:\n",
        "            superstring += node[-1]\n",
        "\n",
        "        # Length should be (k-1) + m\n",
        "        if len(superstring) != k + m - 1:\n",
        "            raise ValueError(\"Full string length incorrect\")\n",
        "\n",
        "        # Trim last (k-1) for minimal cyclic\n",
        "        superstring = superstring[:m]\n",
        "\n",
        "        return superstring\n",
        "\n",
        "    def verify_superstring(self, kmers: List[str], superstring: str) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify if the superstring contains all k-mers cyclically.\n",
        "\n",
        "        Args:\n",
        "            kmers (List[str]): Original k-mers\n",
        "            superstring (str): Reconstructed superstring\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        k = len(kmers[0]) if kmers else 0\n",
        "        n = len(superstring)\n",
        "        generated = set()\n",
        "        for i in range(n):\n",
        "            substr = superstring[i:i+k]\n",
        "            if len(substr) == k:\n",
        "                generated.add(substr)\n",
        "            else:\n",
        "                # Wrap around\n",
        "                wrap = superstring[i:] + superstring[:k - len(superstring[i:])]\n",
        "                generated.add(wrap)\n",
        "        if generated == set(kmers):\n",
        "            return True, \"Valid: Contains all k-mers cyclically\"\n",
        "        return False, f\"Invalid: Missing some k-mers (generated {len(generated)}, expected {len(kmers)})\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Parse input file to extract k-mers.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of k-mers\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            kmers = [line.strip() for line in file if line.strip()]\n",
        "        if not kmers:\n",
        "            raise ValueError(\"No k-mers found in input\")\n",
        "        k = len(kmers[0])\n",
        "        if not all(len(kmer) == k for kmer in kmers):\n",
        "            raise ValueError(\"All k-mers must have the same length\")\n",
        "        return kmers\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "\n",
        "def write_output_file(output_path: str, superstring: str) -> None:\n",
        "    \"\"\"\n",
        "    Write the superstring to output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        superstring (str): Cyclic superstring\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(superstring + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_cyclic_superstring(input_file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Solve the cyclic superstring reconstruction problem.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Input file path\n",
        "\n",
        "    Returns:\n",
        "        str: Minimal cyclic superstring\n",
        "    \"\"\"\n",
        "    try:\n",
        "        kmers = parse_input_file(input_file_path)\n",
        "        print(f\"Parsed {len(kmers)} k-mers of length {len(kmers[0])}\")\n",
        "\n",
        "        reconstructor = CyclicSuperstringReconstructor()\n",
        "        superstring = reconstructor.reconstruct_cyclic_superstring(kmers)\n",
        "\n",
        "        is_valid, msg = reconstructor.verify_superstring(kmers, superstring)\n",
        "        if not is_valid:\n",
        "            raise ValueError(msg)\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return superstring\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the cyclic superstring solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_pcov.txt\"  # Change to your input file name\n",
        "    output_file = \"output_pcov.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Cyclic Superstring Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        superstring = solve_cyclic_superstring(input_file)\n",
        "\n",
        "        # Display result\n",
        "        print(f\"\\nCyclic Superstring: {superstring}\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, superstring)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_cyclic_superstring():\n",
        "    \"\"\"Test with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Cyclic Superstring Reconstructor ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"kmers\": [\"ATTAC\", \"TACAG\", \"GATTA\", \"ACAGA\", \"CAGAT\", \"TTACA\", \"AGATT\"],\n",
        "            \"expected\": \"GATTACA\"\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    reconstructor = CyclicSuperstringReconstructor()\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        kmers = case[\"kmers\"]\n",
        "        expected = case[\"expected\"]\n",
        "        print(f\"\\nTest {i}: {len(kmers)} k-mers\")\n",
        "\n",
        "        superstring = reconstructor.reconstruct_cyclic_superstring(kmers)\n",
        "        print(f\"Reconstructed: {superstring}\")\n",
        "\n",
        "        is_valid, msg = reconstructor.verify_superstring(kmers, superstring)\n",
        "        # Check cyclic equivalence\n",
        "        n = len(expected)\n",
        "        matches_expected = any(superstring == expected[i:] + expected[:i] for i in range(n))\n",
        "        print(f\"Valid: {'✓' if is_valid and matches_expected else '✗'} - {msg} (Matches expected cyclically: {matches_expected})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_cyclic_superstring()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "8wSA8dIWpHiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind De Bruijn Graph with Reverse Complements Solution"
      ],
      "metadata": {
        "id": "pnUBdy_qntGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind De Bruijn Graph with Reverse Complements Solution\n",
        "\n",
        "This module constructs the de Bruijn graph from (k+1)-mers including reverse\n",
        "complements and outputs the adjacency list.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Set, Dict\n",
        "from collections import defaultdict\n",
        "\n",
        "class DeBruijnGraphBuilder:\n",
        "    \"\"\"\n",
        "    A class to build de Bruijn graph from reads and their reverse complements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the graph builder.\"\"\"\n",
        "        self.complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n",
        "\n",
        "    def reverse_complement(self, seq: str) -> str:\n",
        "        \"\"\"\n",
        "        Compute reverse complement of a DNA sequence.\n",
        "\n",
        "        Args:\n",
        "            seq (str): DNA sequence\n",
        "\n",
        "        Returns:\n",
        "            str: Reverse complement\n",
        "        \"\"\"\n",
        "        return ''.join(self.complement[base] for base in reversed(seq))\n",
        "\n",
        "    def build_graph(self, reads: List[str]) -> Dict[str, Set[str]]:\n",
        "        \"\"\"\n",
        "        Build de Bruijn graph adjacency list.\n",
        "\n",
        "        Args:\n",
        "            reads (List[str]): List of (k+1)-mers\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Set[str]]: Adjacency list (prefix -> set of suffixes)\n",
        "        \"\"\"\n",
        "        if not reads:\n",
        "            return {}\n",
        "\n",
        "        k = len(reads[0]) - 1\n",
        "        unique_reads = set(reads)\n",
        "        for read in list(unique_reads):\n",
        "            unique_reads.add(self.reverse_complement(read))\n",
        "\n",
        "        adj = defaultdict(set)\n",
        "        for read in unique_reads:\n",
        "            if len(read) != k + 1:\n",
        "                continue\n",
        "            prefix = read[:-1]\n",
        "            suffix = read[1:]\n",
        "            adj[prefix].add(suffix)\n",
        "\n",
        "        return adj\n",
        "\n",
        "    def get_adjacency_list(self, adj: Dict[str, Set[str]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Get sorted adjacency list in format \"(prefix, suffix)\".\n",
        "\n",
        "        Args:\n",
        "            adj (Dict[str, Set[str]]): Adjacency list\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Sorted list of edge strings\n",
        "        \"\"\"\n",
        "        edges = []\n",
        "        for prefix in sorted(adj):\n",
        "            for suffix in sorted(adj[prefix]):\n",
        "                edges.append(f\"({prefix}, {suffix})\")\n",
        "        return edges\n",
        "\n",
        "    def verify_graph(self, reads: List[str], edges: List[str]) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify the graph against known cases.\n",
        "\n",
        "        Args:\n",
        "            reads (List[str]): Input reads\n",
        "            edges (List[str]): Computed edges\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        # For sample, check if all expected edges are present\n",
        "        expected_sample = set([\n",
        "            \"(ATC, TCA)\", \"(ATG, TGA)\", \"(ATG, TGC)\", \"(CAT, ATC)\",\n",
        "            \"(CAT, ATG)\", \"(GAT, ATG)\", \"(GCA, CAT)\", \"(TCA, CAT)\",\n",
        "            \"(TGA, GAT)\"\n",
        "        ])\n",
        "        computed_set = set(edges)\n",
        "        if computed_set == expected_sample:\n",
        "            return True, \"Valid: Matches expected edges\"\n",
        "        return False, \"Invalid: Does not match expected edges\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Parse input file to extract reads.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of reads\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            reads = [line.strip() for line in file if line.strip()]\n",
        "        if not reads:\n",
        "            raise ValueError(\"No reads found in input\")\n",
        "        length = len(reads[0])\n",
        "        if not all(len(read) == length for read in reads):\n",
        "            raise ValueError(\"All reads must have equal length\")\n",
        "        return reads\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "\n",
        "def write_output_file(output_path: str, edges: List[str]) -> None:\n",
        "    \"\"\"\n",
        "    Write adjacency list to output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        edges (List[str]): List of edge strings\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write('\\n'.join(edges) + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_de_bruijn_graph(input_file_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Solve the de Bruijn graph construction problem.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Input file path\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Adjacency list strings\n",
        "    \"\"\"\n",
        "    try:\n",
        "        reads = parse_input_file(input_file_path)\n",
        "        print(f\"Parsed {len(reads)} reads of length {len(reads[0])}\")\n",
        "\n",
        "        builder = DeBruijnGraphBuilder()\n",
        "        adj = builder.build_graph(reads)\n",
        "        edges = builder.get_adjacency_list(adj)\n",
        "\n",
        "        is_valid, msg = builder.verify_graph(reads, edges)\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return edges\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the de Bruijn graph solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_dbru.txt\"  # Change to your input file name\n",
        "    output_file = \"output_dbru.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving De Bruijn Graph Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        edges = solve_de_bruijn_graph(input_file)\n",
        "\n",
        "        # Display partial result\n",
        "        print(f\"\\nPartial Adjacency List (first 3):\")\n",
        "        for edge in edges[:3]:\n",
        "            print(edge)\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, edges)\n",
        "        print(f\"Full result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_de_bruijn_graph():\n",
        "    \"\"\"Test with sample case.\"\"\"\n",
        "    print(\"=== Testing De Bruijn Graph Builder ===\")\n",
        "\n",
        "    sample_reads = [\"TGAT\", \"CATG\", \"TCAT\", \"ATGC\", \"CATC\", \"CATC\"]\n",
        "    print(\"\\nSample Test:\")\n",
        "\n",
        "    builder = DeBruijnGraphBuilder()\n",
        "    adj = builder.build_graph(sample_reads)\n",
        "    edges = builder.get_adjacency_list(adj)\n",
        "\n",
        "    print(\"Computed Edges:\")\n",
        "    for edge in edges[:3]:\n",
        "        print(edge)\n",
        "\n",
        "    is_valid, msg = builder.verify_graph(sample_reads, edges)\n",
        "    print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run test\n",
        "    test_de_bruijn_graph()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "mzTPCn13npxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind Spectral Convolution Solution"
      ],
      "metadata": {
        "id": "bBZ1S9_cl62L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Spectral Convolution Solution\n",
        "\n",
        "This module computes the Minkowski difference (spectral convolution) of two multisets,\n",
        "finds the difference with maximum multiplicity, and outputs the multiplicity and |x|.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "class SpectralConvolution:\n",
        "    \"\"\"\n",
        "    A class to compute spectral convolution and find max multiplicity.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, precision: int = 5):\n",
        "        \"\"\"Initialize with rounding precision for floats.\"\"\"\n",
        "        self.precision = precision\n",
        "\n",
        "    def compute_convolution(self, s1: List[float], s2: List[float]) -> Dict[float, int]:\n",
        "        \"\"\"\n",
        "        Compute S1 ⊖ S2 as a dict of differences to their multiplicities.\n",
        "\n",
        "        Args:\n",
        "            s1 (List[float]): First multiset\n",
        "            s2 (List[float]): Second multiset\n",
        "\n",
        "        Returns:\n",
        "            Dict[float, int]: Differences rounded, with counts\n",
        "        \"\"\"\n",
        "        diff_count = defaultdict(int)\n",
        "        for val1 in s1:\n",
        "            for val2 in s2:\n",
        "                diff = round(val1 - val2, self.precision)\n",
        "                diff_count[diff] += 1\n",
        "        return diff_count\n",
        "\n",
        "    def find_max_multiplicity(self, diff_count: Dict[float, int]) -> Tuple[int, float]:\n",
        "        \"\"\"\n",
        "        Find the max multiplicity and the absolute value of corresponding x.\n",
        "\n",
        "        Args:\n",
        "            diff_count (Dict[float, int]): Difference counts\n",
        "\n",
        "        Returns:\n",
        "            Tuple[int, float]: (max_multiplicity, abs_x)\n",
        "        \"\"\"\n",
        "        if not diff_count:\n",
        "            return 0, 0.0\n",
        "\n",
        "        max_mult = max(diff_count.values())\n",
        "        # Find any x with max_mult (problem allows any)\n",
        "        max_x = next(x for x, mult in diff_count.items() if mult == max_mult)\n",
        "        return max_mult, abs(max_x)\n",
        "\n",
        "    def verify_convolution(self, s1: List[float], s2: List[float], expected_mult: int, expected_x: float) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify against known cases.\n",
        "\n",
        "        Args:\n",
        "            s1, s2: Multisets\n",
        "            expected_mult: Expected max multiplicity\n",
        "            expected_x: Expected |x|\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        diff_count = self.compute_convolution(s1, s2)\n",
        "        mult, abs_x = self.find_max_multiplicity(diff_count)\n",
        "        if mult == expected_mult and abs(abs_x - expected_x) < 1e-5:\n",
        "            return True, \"Valid: Matches expected\"\n",
        "        return False, f\"Invalid: Got {mult}, {abs_x}; expected {expected_mult}, {expected_x}\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> Tuple[List[float], List[float]]:\n",
        "    \"\"\"\n",
        "    Parse input file: first line S1, second line S2.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[float], List[float]]: S1 and S2\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = [line.strip() for line in file if line.strip()]\n",
        "        if len(lines) != 2:\n",
        "            raise ValueError(\"Input must have exactly two lines\")\n",
        "        s1 = [float(x) for x in lines[0].split()]\n",
        "        s2 = [float(x) for x in lines[1].split()]\n",
        "        return s1, s2\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Invalid numbers in input\")\n",
        "\n",
        "def write_output_file(output_path: str, mult: int, abs_x: float) -> None:\n",
        "    \"\"\"\n",
        "    Write multiplicity and |x| to output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        mult (int): Max multiplicity\n",
        "        abs_x (float): Absolute x\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(f\"{mult}\\n{abs_x}\\n\")\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_spectral_convolution(input_file_path: str) -> Tuple[int, float]:\n",
        "    \"\"\"\n",
        "    Solve the spectral convolution problem.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Input file path\n",
        "\n",
        "    Returns:\n",
        "        Tuple[int, float]: (max_multiplicity, abs_x)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        s1, s2 = parse_input_file(input_file_path)\n",
        "        print(f\"Parsed S1 ({len(s1)} elements), S2 ({len(s2)} elements)\")\n",
        "\n",
        "        conv = SpectralConvolution()\n",
        "        diff_count = conv.compute_convolution(s1, s2)\n",
        "        mult, abs_x = conv.find_max_multiplicity(diff_count)\n",
        "\n",
        "        return mult, abs_x\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the spectral convolution solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_conv.txt\"  # Change to your input file name\n",
        "    output_file = \"output_conv.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Spectral Convolution Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        mult, abs_x = solve_spectral_convolution(input_file)\n",
        "\n",
        "        # Display result\n",
        "        print(f\"\\nMax Multiplicity: {mult}\")\n",
        "        print(f\"Absolute x: {abs_x}\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, mult, abs_x)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_spectral_convolution():\n",
        "    \"\"\"Test with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Spectral Convolution ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"s1\": [186.07931, 287.12699, 548.20532, 580.18077, 681.22845, 706.27446, 782.27613, 968.35544, 968.35544],\n",
        "            \"s2\": [101.04768, 158.06914, 202.09536, 318.09979, 419.14747, 463.17369],\n",
        "            \"expected_mult\": 3,\n",
        "            \"expected_x\": 85.03163\n",
        "        },\n",
        "        {\"s1\": [1.0, 2.0], \"s2\": [1.0], \"expected_mult\": 1, \"expected_x\": 0.0},  # Simple case\n",
        "    ]\n",
        "\n",
        "    conv = SpectralConvolution()\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        s1 = case[\"s1\"]\n",
        "        s2 = case[\"s2\"]\n",
        "        print(f\"\\nTest {i}: S1={s1[:3]}..., S2={s2[:3]}...\")\n",
        "\n",
        "        diff_count = conv.compute_convolution(s1, s2)\n",
        "        mult, abs_x = conv.find_max_multiplicity(diff_count)\n",
        "        print(f\"Max Multiplicity: {mult}, Abs x: {abs_x}\")\n",
        "\n",
        "        is_valid, msg = conv.verify_convolution(s1, s2, case[\"expected_mult\"], case[\"expected_x\"])\n",
        "        print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_spectral_convolution()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "BDm0WTKol25O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein Reconstruction from Prefix Spectrum Solution"
      ],
      "metadata": {
        "id": "waZhdWHvfmlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Protein Reconstruction from Prefix Spectrum Solution (Corrected)\n",
        "\n",
        "This module reconstructs a protein string from a list of prefix masses using\n",
        "the monoisotopic mass table, computing consecutive differences.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class ProteinReconstructor:\n",
        "    \"\"\"\n",
        "    A class to reconstruct protein from prefix spectrum.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize with monoisotopic mass table.\"\"\"\n",
        "        self.mass_table = {\n",
        "            'A': 71.03711, 'C': 103.00919, 'D': 115.02694, 'E': 129.04259,\n",
        "            'F': 147.06841, 'G': 57.02146, 'H': 137.05891, 'I': 113.08406,\n",
        "            'K': 128.09496, 'L': 113.08406, 'M': 131.04049, 'N': 114.04293,\n",
        "            'P': 97.05276, 'Q': 128.05858, 'R': 156.10111, 'S': 87.03203,\n",
        "            'T': 101.04768, 'V': 99.06841, 'W': 186.07931, 'Y': 163.06333\n",
        "        }\n",
        "\n",
        "    def reconstruct_protein(self, masses: List[float]) -> str:\n",
        "        \"\"\"\n",
        "        Reconstruct protein string from prefix masses by computing differences.\n",
        "\n",
        "        Args:\n",
        "            masses (List[float]): List of prefix masses\n",
        "\n",
        "        Returns:\n",
        "            str: Protein string\n",
        "        \"\"\"\n",
        "        if len(masses) < 2:\n",
        "            return \"\"\n",
        "\n",
        "        # Sort masses to ensure increasing prefix order\n",
        "        masses = sorted(masses)\n",
        "\n",
        "        protein = []\n",
        "        for i in range(1, len(masses)):\n",
        "            diff = round(masses[i] - masses[i-1], 5)\n",
        "            # Find closest matching mass\n",
        "            closest = min(self.mass_table, key=lambda aa: abs(self.mass_table[aa] - diff))\n",
        "            if abs(self.mass_table[closest] - diff) > 0.001:\n",
        "                raise ValueError(f\"No amino acid matches mass diff {diff}\")\n",
        "            protein.append(closest)\n",
        "\n",
        "        return ''.join(protein)\n",
        "\n",
        "    def verify_reconstruction(self, masses: List[float], protein: str) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify by checking if differences in masses match amino acid masses.\n",
        "\n",
        "        Args:\n",
        "            masses (List[float]): Original masses\n",
        "            protein (str): Reconstructed protein\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        sorted_masses = sorted(masses)\n",
        "        computed_diffs = [round(sorted_masses[i] - sorted_masses[i-1], 5) for i in range(1, len(masses))]\n",
        "        protein_diffs = [round(self.mass_table[aa], 5) for aa in protein]\n",
        "        if computed_diffs == protein_diffs:\n",
        "            return True, \"Valid: Differences match amino acid masses\"\n",
        "        return False, f\"Invalid: Differences do not match (computed {computed_diffs}, protein {protein_diffs})\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    Parse input file to extract list of masses.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        List[float]: List of masses\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = [line.strip() for line in file if line.strip() and not line.startswith('>')]\n",
        "        masses = [float(line) for line in lines]\n",
        "        return masses\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Invalid mass value in input\")\n",
        "\n",
        "def write_output_file(output_path: str, protein: str) -> None:\n",
        "    \"\"\"\n",
        "    Write the protein string to output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        protein (str): Protein string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(protein + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_protein_reconstruction(input_file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Solve the protein reconstruction problem.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Input file path\n",
        "\n",
        "    Returns:\n",
        "        str: Reconstructed protein\n",
        "    \"\"\"\n",
        "    try:\n",
        "        masses = parse_input_file(input_file_path)\n",
        "        print(f\"Parsed {len(masses)} masses\")\n",
        "\n",
        "        reconstructor = ProteinReconstructor()\n",
        "        protein = reconstructor.reconstruct_protein(masses)\n",
        "\n",
        "        is_valid, msg = reconstructor.verify_reconstruction(masses, protein)\n",
        "        if not is_valid:\n",
        "            raise ValueError(msg)\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return protein\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the protein reconstruction solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_spec.txt\"  # Standard Rosalind ID for this problem\n",
        "    output_file = \"output_spec.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Protein Reconstruction Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        protein = solve_protein_reconstruction(input_file)\n",
        "\n",
        "        # Display result\n",
        "        print(f\"\\nReconstructed Protein: {protein}\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, protein)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_protein_reconstruction():\n",
        "    \"\"\"Test with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Protein Reconstructor ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\"masses\": [3524.8542, 3710.9335, 3841.974, 3970.0326, 4057.0646], \"expected\": \"WMQS\"},\n",
        "        {\"masses\": [3710.9335, 3841.974, 3970.0326, 4057.0646, 4243.1439], \"expected\": \"WMQSW\"},  # Hypothetical extension\n",
        "    ]\n",
        "\n",
        "    reconstructor = ProteinReconstructor()\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        masses = case[\"masses\"]\n",
        "        expected = case[\"expected\"]\n",
        "        print(f\"\\nTest {i}: Masses={masses}\")\n",
        "\n",
        "        protein = reconstructor.reconstruct_protein(masses)\n",
        "        print(f\"Reconstructed: {protein}\")\n",
        "\n",
        "        is_valid, msg = reconstructor.verify_reconstruction(masses, protein)\n",
        "        matches_expected = protein == expected\n",
        "        print(f\"Valid: {'✓' if is_valid and matches_expected else '✗'} - {msg} (Matches expected: {matches_expected})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_protein_reconstruction()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "n0nvgTU3fcBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind Failure Array (KMP Prefix Table) Solution"
      ],
      "metadata": {
        "id": "o95x4cF9d0SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Failure Array (KMP Prefix Table) Solution\n",
        "\n",
        "This module computes the failure array for a DNA string using the Knuth-Morris-Pratt algorithm.\n",
        "It handles FASTA input and outputs the array as space-separated integers.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "class FailureArrayComputer:\n",
        "    \"\"\"\n",
        "    A class to compute the KMP failure array for a string.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the failure array computer.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def compute_failure_array(self, s: str) -> List[int]:\n",
        "        \"\"\"\n",
        "        Compute the failure array (prefix table) for the KMP algorithm.\n",
        "\n",
        "        Args:\n",
        "            s (str): Input string\n",
        "\n",
        "        Returns:\n",
        "            List[int]: Failure array P where P[i] is the longest proper prefix-suffix match for s[0..i]\n",
        "        \"\"\"\n",
        "        n = len(s)\n",
        "        if n == 0:\n",
        "            return []\n",
        "\n",
        "        pi = [0] * n\n",
        "        j = 0  # Length of previous longest prefix suffix\n",
        "\n",
        "        for i in range(1, n):\n",
        "            while j > 0 and s[i] != s[j]:\n",
        "                j = pi[j - 1]\n",
        "            if s[i] == s[j]:\n",
        "                j += 1\n",
        "            pi[i] = j\n",
        "\n",
        "        return pi\n",
        "\n",
        "    def verify_failure_array(self, s: str, pi: List[int]) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify the failure array against known cases.\n",
        "\n",
        "        Args:\n",
        "            s (str): Input string\n",
        "            pi (List[int]): Computed failure array\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        known_cases = {\n",
        "            \"CAGCATGGTATCACAGCAGAG\": [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 3, 4, 5, 3, 0, 0],\n",
        "            \"AAA\": [0, 1, 2],\n",
        "            \"ABC\": [0, 0, 0],\n",
        "            \"\": []\n",
        "        }\n",
        "        if s in known_cases:\n",
        "            expected = known_cases[s]\n",
        "            if pi == expected:\n",
        "                return True, \"Valid: Matches expected array\"\n",
        "            return False, f\"Invalid: Expected {expected}, got {pi}\"\n",
        "        return True, \"No verification available for this input\"\n",
        "\n",
        "def parse_fasta_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Parse FASTA file to extract the DNA sequence.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        str: Concatenated DNA sequence\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = [line.strip() for line in file]\n",
        "        sequence = ''\n",
        "        in_sequence = False\n",
        "        for line in lines:\n",
        "            if line.startswith('>'):\n",
        "                in_sequence = True\n",
        "                continue\n",
        "            if in_sequence:\n",
        "                sequence += line\n",
        "        if not sequence:\n",
        "            raise ValueError(\"No sequence found in FASTA file\")\n",
        "        return sequence\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "\n",
        "def write_output_file(output_path: str, pi: List[int]) -> None:\n",
        "    \"\"\"\n",
        "    Write the failure array to the output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        pi (List[int]): Failure array\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(' '.join(map(str, pi)) + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_failure_array_problem(input_file_path: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Solve the failure array problem for the given input file.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Path to FASTA input file\n",
        "\n",
        "    Returns:\n",
        "        List[int]: Computed failure array\n",
        "    \"\"\"\n",
        "    try:\n",
        "        s = parse_fasta_file(input_file_path)\n",
        "        print(f\"Parsed sequence: length={len(s)}\")\n",
        "\n",
        "        computer = FailureArrayComputer()\n",
        "        pi = computer.compute_failure_array(s)\n",
        "\n",
        "        is_valid, msg = computer.verify_failure_array(s, pi)\n",
        "        if not is_valid:\n",
        "            raise ValueError(msg)\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return pi\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the failure array solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_kmp.txt\"  # Change this to your input file name\n",
        "    output_file = \"output_kmp.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Failure Array Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        pi = solve_failure_array_problem(input_file)\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\nResult (first 10 values): {' '.join(map(str, pi[:10]))} ...\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, pi)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        print(\"Please make sure the file exists in the current directory.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_failure_array():\n",
        "    \"\"\"Test the failure array computation with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Failure Array Computer ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\"s\": \"CAGCATGGTATCACAGCAGAG\"},\n",
        "        {\"s\": \"AAA\"},\n",
        "        {\"s\": \"ABC\"},\n",
        "        {\"s\": \"\"},\n",
        "    ]\n",
        "\n",
        "    computer = FailureArrayComputer()\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        s = case[\"s\"]\n",
        "        print(f\"\\nTest {i}: s={s}\")\n",
        "\n",
        "        pi = computer.compute_failure_array(s)\n",
        "        print(f\"Failure array: {pi}\")\n",
        "\n",
        "        is_valid, msg = computer.verify_failure_array(s, pi)\n",
        "        print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_failure_array()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "m9oPFS9jd3I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind 4-mer Composition Solution"
      ],
      "metadata": {
        "id": "X1gviS9Vdy5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind 4-mer Composition Solution\n",
        "\n",
        "This module computes the 4-mer composition of a DNA string, counting occurrences\n",
        "of all possible 4-mers in lexicographic order.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict\n",
        "from itertools import product\n",
        "\n",
        "class KmerComposer:\n",
        "    \"\"\"\n",
        "    A class to compute k-mer composition of a DNA string.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k: int = 4):\n",
        "        \"\"\"Initialize with k-mer length.\"\"\"\n",
        "        self.k = k\n",
        "        self.alphabet = ['A', 'C', 'G', 'T']\n",
        "\n",
        "    def generate_all_kmers(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate all possible k-mers in lexicographic order.\n",
        "\n",
        "        Returns:\n",
        "            List[str]: Sorted list of all k-mers.\n",
        "        \"\"\"\n",
        "        kmers = [''.join(p) for p in product(self.alphabet, repeat=self.k)]\n",
        "        return sorted(kmers)\n",
        "\n",
        "    def count_kmers(self, dna: str) -> Dict[str, int]:\n",
        "        \"\"\"\n",
        "        Count occurrences of each k-mer in the DNA string (overlapping).\n",
        "\n",
        "        Args:\n",
        "            dna (str): DNA sequence.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, int]: Counts for each k-mer.\n",
        "        \"\"\"\n",
        "        if len(dna) < self.k:\n",
        "            return {}\n",
        "\n",
        "        counts = {kmer: 0 for kmer in self.generate_all_kmers()}\n",
        "        for i in range(len(dna) - self.k + 1):\n",
        "            substring = dna[i:i + self.k]\n",
        "            if substring in counts:\n",
        "                counts[substring] += 1\n",
        "        return counts\n",
        "\n",
        "    def get_composition(self, dna: str) -> List[int]:\n",
        "        \"\"\"\n",
        "        Get the composition as a list of counts in lex order.\n",
        "\n",
        "        Args:\n",
        "            dna (str): DNA sequence.\n",
        "\n",
        "        Returns:\n",
        "            List[int]: Counts in order.\n",
        "        \"\"\"\n",
        "        counts = self.count_kmers(dna)\n",
        "        all_kmers = self.generate_all_kmers()\n",
        "        return [counts.get(kmer, 0) for kmer in all_kmers]\n",
        "\n",
        "    def verify_composition(self, dna: str, composition: List[int]) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify composition for small test cases.\n",
        "\n",
        "        Args:\n",
        "            dna (str): DNA sequence\n",
        "            composition (List[int]): Computed composition\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, message)\n",
        "        \"\"\"\n",
        "        # Example: For dna=\"CTGA\", 2-mers: AA=0, AC=0, ..., TG=1, TT=0 (adapt for 4-mer if needed)\n",
        "        # For simplicity, check sum equals expected number of k-mers\n",
        "        expected_count = max(0, len(dna) - self.k + 1)\n",
        "        total = sum(composition)\n",
        "        if total == expected_count:\n",
        "            return True, f\"Valid: Total counts match {expected_count}\"\n",
        "        return False, f\"Invalid: Total {total}, expected {expected_count}\"\n",
        "\n",
        "def parse_fasta_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Parse FASTA file to extract DNA sequence.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        str: Concatenated DNA sequence\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "        sequence = ''\n",
        "        for line in lines:\n",
        "            if not line.startswith('>'):\n",
        "                sequence += line.strip()\n",
        "        if not all(base in 'ACGT' for base in sequence):\n",
        "            raise ValueError(\"Invalid DNA sequence: only A, C, G, T allowed\")\n",
        "        return sequence\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "\n",
        "def write_output_file(output_path: str, composition: List[int]) -> None:\n",
        "    \"\"\"\n",
        "    Write composition to output file as space-separated integers.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        composition (List[int]): List of counts\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(' '.join(map(str, composition)) + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_kmer_composition(input_file_path: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Solve the k-mer composition problem.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Input FASTA file path\n",
        "\n",
        "    Returns:\n",
        "        List[int]: 4-mer composition\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dna = parse_fasta_file(input_file_path)\n",
        "        print(f\"Parsed DNA: length={len(dna)}\")\n",
        "\n",
        "        composer = KmerComposer(k=4)\n",
        "        composition = composer.get_composition(dna)\n",
        "\n",
        "        is_valid, msg = composer.verify_composition(dna, composition)\n",
        "        if not is_valid:\n",
        "            raise ValueError(msg)\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return composition\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the k-mer composition solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_kmer.txt\"  # Change to your input file name\n",
        "    output_file = \"output_kmer.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving 4-mer Composition Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        composition = solve_kmer_composition(input_file)\n",
        "\n",
        "        # Display partial results (first 10 for brevity)\n",
        "        print(f\"\\nPartial Result (first 10 counts): {' '.join(map(str, composition[:10]))}\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, composition)\n",
        "        print(f\"Full result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_kmer_composition():\n",
        "    \"\"\"Test the k-mer composer with small cases.\"\"\"\n",
        "    print(\"=== Testing K-mer Composer ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\"dna\": \"CTGA\", \"k\": 2, \"expected_total\": 3},  # CT, TG, GA\n",
        "        {\"dna\": \"AAAA\", \"k\": 4, \"expected_count_AAAA\": 1},\n",
        "    ]\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        composer = KmerComposer(k=case[\"k\"])\n",
        "        composition = composer.get_composition(case[\"dna\"])\n",
        "        total = sum(composition)\n",
        "        print(f\"\\nTest {i}: DNA={case['dna']}, k={case['k']}\")\n",
        "        print(f\"Total k-mers counted: {total}\")\n",
        "        is_valid, msg = composer.verify_composition(case[\"dna\"], composition)\n",
        "        print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_kmer_composition()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GQDd182yazEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Counting Valid RNA Secondary Structures with Wobble Pairs"
      ],
      "metadata": {
        "id": "RskV9013ZPfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Counting Valid RNA Secondary Structures with Wobble Pairs\n",
        "\n",
        "This module uses iterative dynamic programming to count valid noncrossing matchings\n",
        "in RNA bonding graphs, allowing wobble pairs and minimum distance constraints.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "class RNAMatchingCounter:\n",
        "    \"\"\"\n",
        "    Class to count valid RNA matchings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize base pair rules.\"\"\"\n",
        "        self.base_pairs = {\n",
        "            ('A', 'U'), ('U', 'A'),\n",
        "            ('C', 'G'), ('G', 'C'),\n",
        "            ('G', 'U'), ('U', 'G')\n",
        "        }\n",
        "\n",
        "    def can_pair(self, base1: str, base2: str) -> bool:\n",
        "        \"\"\"Check if two bases can pair.\"\"\"\n",
        "        return (base1, base2) in self.base_pairs\n",
        "\n",
        "    def count_valid_matchings(self, rna: str) -> int:\n",
        "        \"\"\"\n",
        "        Count valid matchings using 2D DP.\n",
        "\n",
        "        dp[i][j]: number of valid matchings for subsequence rna[i..j]\n",
        "        \"\"\"\n",
        "        n = len(rna)\n",
        "        if n == 0:\n",
        "            return 1\n",
        "\n",
        "        dp: List[List[int]] = [[0] * n for _ in range(n)]\n",
        "\n",
        "        # Base cases: single base or empty\n",
        "        for i in range(n):\n",
        "            dp[i][i] = 1  # Unpaired single base\n",
        "\n",
        "        for length in range(1, n):\n",
        "            for i in range(n - length):\n",
        "                j = i + length\n",
        "                # Case: j is unpaired\n",
        "                dp[i][j] = dp[i][j - 1]\n",
        "                # Case: j pairs with some k\n",
        "                for k in range(i, j):\n",
        "                    if self.can_pair(rna[k], rna[j]) and (j - k) >= 4:\n",
        "                        left = dp[i][k - 1] if k > i else 1\n",
        "                        inside = dp[k + 1][j - 1] if k + 1 <= j - 1 else 1\n",
        "                        dp[i][j] += left * inside\n",
        "\n",
        "        return dp[0][n - 1]\n",
        "\n",
        "    def verify_count(self, rna: str, count: int) -> Tuple[bool, str]:\n",
        "        \"\"\"Verify against known small cases.\"\"\"\n",
        "        known = {\n",
        "            \"CGAUGCUAG\": 12,\n",
        "            \"AU\": 1,\n",
        "            \"AUGC\": 1,\n",
        "            \"AUGCAU\": 2,\n",
        "            \"AUGCUAGUACGGAGCGAGUCUAGCGAGCGAUGUCGUGAGUACUAUAUAUGCGCAUAAGCCACGU\": 284850219977421\n",
        "        }\n",
        "        if rna in known:\n",
        "            if count == known[rna]:\n",
        "                return True, \"Valid: Matches expected\"\n",
        "            return False, f\"Invalid: Expected {known[rna]}, got {count}\"\n",
        "        return True, \"No verification available\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> str:\n",
        "    \"\"\"Parse RNA from file.\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        rna = ''.join(line.strip() for line in f if line.strip())\n",
        "    if not all(b in 'AUGC' for b in rna):\n",
        "        raise ValueError(\"Invalid RNA sequence\")\n",
        "    return rna\n",
        "\n",
        "def write_output_file(output_path: str, result: int) -> None:\n",
        "    \"\"\"Write result to file.\"\"\"\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(str(result) + '\\n')\n",
        "\n",
        "def solve_problem(input_file: str, output_file: str) -> None:\n",
        "    \"\"\"Solve and output.\"\"\"\n",
        "    rna = parse_input_file('/content/rosalind_rnas.txt')\n",
        "    counter = RNAMatchingCounter()\n",
        "    result = counter.count_valid_matchings(rna)\n",
        "    is_valid, msg = counter.verify_count(rna, result)\n",
        "    if not is_valid:\n",
        "        raise ValueError(msg)\n",
        "    write_output_file(output_file, result)\n",
        "    print(f\"Result: {result} (Verification: {msg})\")\n",
        "\n",
        "# Usage example (adjust file names as needed)\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"rosalind_input.txt\"\n",
        "    output_file = \"rosalind_output.txt\"\n",
        "    solve_problem(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "7BB2txMESJBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rosalind Distances in Trees Problem"
      ],
      "metadata": {
        "id": "ovByVCNYQq5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Node:\n",
        "    \"\"\"A simple class to represent a node in a tree.\"\"\"\n",
        "    def __init__(self, name=None, parent=None):\n",
        "        self.name = name\n",
        "        self.parent = parent\n",
        "        self.children = []\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Node({self.name})\"\n",
        "\n",
        "def parse_newick(newick_string):\n",
        "    \"\"\"\n",
        "    Parses a Newick format string into a tree of Node objects.\n",
        "\n",
        "    Returns a dictionary mapping all named nodes to their Node objects.\n",
        "    \"\"\"\n",
        "    # Clean up the string by removing the final semicolon and any whitespace\n",
        "    tokens = re.split(r'([,();])', newick_string.strip())\n",
        "    tokens = [t.strip() for t in tokens if t.strip()]\n",
        "\n",
        "    root = Node()\n",
        "    current_node = root\n",
        "    nodes_map = {}\n",
        "\n",
        "    # Counter for generating unique names for internal nodes that are not explicitly named\n",
        "    internal_node_counter = 0\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == '(':\n",
        "            # Start of a new set of children. Create a new child node.\n",
        "            # If the current node doesn't have a name yet, it's an internal node.\n",
        "            if current_node.name is None:\n",
        "                current_node.name = f\"internal_{internal_node_counter}\"\n",
        "                internal_node_counter += 1\n",
        "            if current_node.name not in nodes_map:\n",
        "                nodes_map[current_node.name] = current_node\n",
        "\n",
        "            # Create a new child and descend into it\n",
        "            new_child = Node(parent=current_node)\n",
        "            current_node.children.append(new_child)\n",
        "            current_node = new_child\n",
        "\n",
        "        elif token == ',':\n",
        "            # A sibling follows. Go back to the parent to add the next sibling.\n",
        "            current_node = current_node.parent\n",
        "            new_sibling = Node(parent=current_node)\n",
        "            current_node.children.append(new_sibling)\n",
        "            current_node = new_sibling\n",
        "\n",
        "        elif token == ')':\n",
        "            # End of a children list. Go back to the parent.\n",
        "            current_node = current_node.parent\n",
        "\n",
        "        elif token == ';':\n",
        "            # End of the entire tree string\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            # This token is a name for the current node.\n",
        "            current_node.name = token\n",
        "            nodes_map[token] = current_node\n",
        "\n",
        "    # If the root node was a simple leaf (e.g., \"dog;\"), it won't be in the map yet.\n",
        "    if root.name and root.name not in nodes_map:\n",
        "        nodes_map[root.name] = root\n",
        "\n",
        "    return nodes_map\n",
        "\n",
        "def solve_paths_in_trees_no_bio():\n",
        "    \"\"\"\n",
        "    Reads trees, calculates distances without Biopython, and writes results.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open('rosalind_nwck.txt', 'r') as f:\n",
        "            data_sets = f.read().strip().split('\\n\\n')\n",
        "\n",
        "        distances = []\n",
        "\n",
        "        for data_set in data_sets:\n",
        "            if not data_set:\n",
        "                continue\n",
        "\n",
        "            newick_string, nodes_line = data_set.strip().split('\\n')\n",
        "            node1_name, node2_name = nodes_line.split()\n",
        "\n",
        "            # Step 1: Parse the Newick string into a tree\n",
        "            nodes_map = parse_newick(newick_string)\n",
        "\n",
        "            # Get the node objects from the map\n",
        "            node1 = nodes_map[node1_name]\n",
        "            node2 = nodes_map[node2_name]\n",
        "\n",
        "            # Step 2: Find the path from node1 to the root\n",
        "            path_to_root1 = []\n",
        "            curr = node1\n",
        "            while curr:\n",
        "                path_to_root1.append(curr)\n",
        "                curr = curr.parent\n",
        "\n",
        "            # Create a set for quick lookups of ancestors\n",
        "            ancestors1 = set(path_to_root1)\n",
        "\n",
        "            # Step 3: Find the LCA by traversing from node2 to the root\n",
        "            lca = None\n",
        "            path_to_lca2 = []\n",
        "            curr = node2\n",
        "            while curr:\n",
        "                path_to_lca2.append(curr)\n",
        "                if curr in ancestors1:\n",
        "                    lca = curr\n",
        "                    break\n",
        "                curr = curr.parent\n",
        "\n",
        "            # Step 4: Calculate the distance\n",
        "            # The distance is the number of edges, which is (path_len1 - 1) + (path_len2 - 1)\n",
        "            dist1 = path_to_root1.index(lca)\n",
        "            dist2 = path_to_lca2.index(lca)\n",
        "            total_distance = dist1 + dist2\n",
        "            distances.append(str(total_distance))\n",
        "\n",
        "        with open('output_nwck.txt', 'w') as f:\n",
        "            f.write(' '.join(distances))\n",
        "\n",
        "        print(\"Processing complete. Results are in 'output_nwck.txt'.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'rosalind_nwck.txt' not found.\")\n",
        "        print(\"Please create the file and add your input data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Execute the function\n",
        "solve_paths_in_trees_no_bio()\n",
        "\n"
      ],
      "metadata": {
        "id": "GURw2sXQNUl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motzkin Numbers and RNA Secondary Structures"
      ],
      "metadata": {
        "id": "pwFnEwLHErUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Motzkin Numbers and RNA Secondary Structures Solution\n",
        "\n",
        "This module implements a dynamic programming approach based on Motzkin numbers\n",
        "to count noncrossing matchings in RNA secondary structures. It handles large inputs\n",
        "efficiently and includes verification for correctness.\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "class MotzkinRNA:\n",
        "    \"\"\"\n",
        "    A class to compute the number of noncrossing matchings in RNA secondary structures\n",
        "    using a modified Motzkin recurrence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Motzkin RNA counter with base pair rules.\"\"\"\n",
        "        self.base_pairs = {('A', 'U'), ('U', 'A'), ('G', 'C'), ('C', 'G')}\n",
        "        self.mod = 1000000\n",
        "\n",
        "    def can_pair(self, base1: str, base2: str) -> bool:\n",
        "        \"\"\"\n",
        "        Check if two RNA bases can form a pair.\n",
        "\n",
        "        Args:\n",
        "            base1 (str): First RNA base\n",
        "            base2 (str): Second RNA base\n",
        "\n",
        "        Returns:\n",
        "            bool: True if bases can pair, False otherwise\n",
        "        \"\"\"\n",
        "        return (base1, base2) in self.base_pairs\n",
        "\n",
        "    def count_noncrossing_matchings(self, rna: str) -> int:\n",
        "        \"\"\"\n",
        "        Count the number of noncrossing matchings in the RNA bonding graph using\n",
        "        dynamic programming based on Motzkin numbers.\n",
        "\n",
        "        Args:\n",
        "            rna (str): RNA sequence\n",
        "\n",
        "        Returns:\n",
        "            int: Number of noncrossing matchings modulo 1,000,000\n",
        "        \"\"\"\n",
        "        n = len(rna)\n",
        "        if n == 0:\n",
        "            return 1\n",
        "\n",
        "        # dp[i][j] represents the number of noncrossing matchings for subsequence i to j\n",
        "        dp = [[0] * n for _ in range(n)]\n",
        "\n",
        "        # Initialize base cases for single and empty subsequences\n",
        "        for i in range(n):\n",
        "            dp[i][i] = 1  # Single base, no pairing\n",
        "            if i + 1 < n:\n",
        "                dp[i][i+1] = 1  # Two bases, no pairing yet\n",
        "\n",
        "        # Fill the dp table for subsequences of length 2 to n\n",
        "        for length in range(2, n + 1):\n",
        "            for start in range(n - length + 1):\n",
        "                end = start + length - 1\n",
        "                # Case 1: Last base is unpaired\n",
        "                dp[start][end] = dp[start][end - 1]\n",
        "\n",
        "                # Case 2: Last base pairs with some base k\n",
        "                for k in range(start, end):\n",
        "                    if self.can_pair(rna[k], rna[end]):\n",
        "                        if k == start:\n",
        "                            # Pairing with first base, count inside\n",
        "                            inside = dp[start + 1][end - 1] if start + 1 <= end - 1 else 1\n",
        "                            dp[start][end] = (dp[start][end] + inside) % self.mod\n",
        "                        else:\n",
        "                            # Split into two parts: start to k-1 and k+1 to end-1\n",
        "                            left = dp[start][k - 1] if start <= k - 1 else 1\n",
        "                            right = dp[k + 1][end - 1] if k + 1 <= end - 1 else 1\n",
        "                            dp[start][end] = (dp[start][end] + left * right) % self.mod\n",
        "\n",
        "        return dp[0][n - 1]\n",
        "\n",
        "    def verify_count(self, rna: str, count: int) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify the count of noncrossing matchings for small test cases.\n",
        "\n",
        "        Args:\n",
        "            rna (str): RNA sequence\n",
        "            count (int): Computed number of matchings\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        # For small known cases, verify against expected output\n",
        "        known_cases = {\n",
        "            \"AUAU\": 7,\n",
        "            \"AU\": 2,\n",
        "            \"A\": 1,\n",
        "            \"\": 1\n",
        "        }\n",
        "        if rna in known_cases:\n",
        "            expected = known_cases[rna]\n",
        "            if count == expected:\n",
        "                return True, f\"Valid: Matches expected count {expected} for {rna}\"\n",
        "            return False, f\"Invalid: Expected {expected} for {rna}, got {count}\"\n",
        "        return True, \"No verification for this input (unknown case)\"\n",
        "\n",
        "def parse_input_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Parse input file to extract RNA sequence.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        str: RNA sequence\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "        if not lines:\n",
        "            raise ValueError(\"Input file is empty\")\n",
        "\n",
        "        # Skip the header line if it starts with '>'\n",
        "        rna = ''.join(lines[1:]) if lines[0].startswith('>') else ''.join(lines)\n",
        "        if not all(base in 'AUGC' for base in rna):\n",
        "            raise ValueError(\"Invalid RNA sequence: must contain only A, U, G, C\")\n",
        "        return rna\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Input parsing error: {e}\")\n",
        "\n",
        "def write_output_file(output_path: str, result: int) -> None:\n",
        "    \"\"\"\n",
        "    Write the result to the output file.\n",
        "\n",
        "    Args:\n",
        "        output_path (str): Path to output file\n",
        "        result (int): Number of noncrossing matchings\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(str(result) + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "def solve_motzkin_rna_problem(input_file_path: str) -> int:\n",
        "    \"\"\"\n",
        "    Solve the Motzkin RNA problem for a given input file.\n",
        "\n",
        "    Args:\n",
        "        input_file_path (str): Path to input file\n",
        "\n",
        "    Returns:\n",
        "        int: Number of noncrossing matchings modulo 1,000,000\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse input\n",
        "        rna = parse_input_file(input_file_path)\n",
        "        print(f\"Parsed input: RNA sequence = {rna[:10]}... (length={len(rna)})\")\n",
        "\n",
        "        # Initialize Motzkin counter\n",
        "        counter = MotzkinRNA()\n",
        "\n",
        "        # Compute the number of noncrossing matchings\n",
        "        result = counter.count_noncrossing_matchings(rna)\n",
        "\n",
        "        # Verify for small cases\n",
        "        is_valid, msg = counter.verify_count(rna, result)\n",
        "        if not is_valid:\n",
        "            raise ValueError(f\"Invalid result: {msg}\")\n",
        "        print(f\"Verification: {msg}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the Motzkin RNA problem solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_motz.txt\"  # Change this to your input file name\n",
        "    output_file = \"output_motz.txt\"\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Motzkin RNA Secondary Structures Problem...\")\n",
        "\n",
        "        # Solve the problem\n",
        "        result = solve_motzkin_rna_problem(input_file)\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\nResult:\")\n",
        "        print(f\"Number of noncrossing matchings (mod 1,000,000): {result}\")\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, result)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        print(\"Please make sure the file exists in the current directory.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "def test_motzkin_rna():\n",
        "    \"\"\"Test the Motzkin RNA counter with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Motzkin RNA Counter ===\")\n",
        "\n",
        "    test_cases = [\n",
        "        {\"rna\": \"AUAU\", \"expected\": 7},\n",
        "        {\"rna\": \"AU\", \"expected\": 2},\n",
        "        {\"rna\": \"A\", \"expected\": 1},\n",
        "        {\"rna\": \"GC\", \"expected\": 2},\n",
        "        {\"rna\": \"AA\", \"expected\": 1},  # Can't pair\n",
        "        {\"rna\": \"AUAUAU\", \"expected\": 22},\n",
        "    ]\n",
        "\n",
        "    counter = MotzkinRNA()\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        rna = case[\"rna\"]\n",
        "        expected = case.get(\"expected\", None)\n",
        "        print(f\"\\nTest {i}: RNA={rna}\")\n",
        "\n",
        "        result = counter.count_noncrossing_matchings(rna)\n",
        "        print(f\"Result: {result}\")\n",
        "\n",
        "        is_valid, msg = counter.verify_count(rna, result)\n",
        "        print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "        if expected is not None and result == expected:\n",
        "            print(f\"Matches expected {expected}: ✓\")\n",
        "        elif expected is not None:\n",
        "            print(f\"Matches expected {expected}: ✗\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_motzkin_rna()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "8XPLJEjyEtCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majority Element Problem"
      ],
      "metadata": {
        "id": "ixw2Q_U2-iV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Rosalind Majority Element Problem Solution\n",
        "\n",
        "\n",
        "This module implements a divide-and-conquer algorithm to find the majority element\n",
        "in multiple arrays. It handles large inputs efficiently and includes verification for correctness.\n",
        "\n",
        "\n",
        "Author: Bioinformatics Solution\n",
        "Compatible with: Python 3.6+\n",
        "Platform: Google Colab\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "\n",
        "class MajorityFinder:\n",
        "    \"\"\"\n",
        "    A class to find the majority element in an array using divide-and-conquer.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the majority finder.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def find_majority(self, arr: List[int]) -> int:\n",
        "        \"\"\"\n",
        "        Find the majority element in the array using divide-and-conquer.\n",
        "\n",
        "\n",
        "        A majority element appears more than n/2 times.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            arr (List[int]): Input array\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            int: The majority element if it exists, -1 otherwise\n",
        "        \"\"\"\n",
        "        if not arr:\n",
        "            return -1\n",
        "\n",
        "\n",
        "        def majority_rec(start: int, end: int) -> int:\n",
        "            if start == end:\n",
        "                return arr[start]\n",
        "\n",
        "\n",
        "            mid = (start + end) // 2\n",
        "            left_major = majority_rec(start, mid)\n",
        "            right_major = majority_rec(mid + 1, end)\n",
        "\n",
        "\n",
        "            if left_major == right_major:\n",
        "                return left_major\n",
        "\n",
        "\n",
        "            # Count occurrences in the range\n",
        "            left_count = sum(1 for i in range(start, end + 1) if arr[i] == left_major)\n",
        "            right_count = sum(1 for i in range(start, end + 1) if arr[i] == right_major)\n",
        "\n",
        "\n",
        "            if left_count > (end - start + 1) // 2:\n",
        "                return left_major\n",
        "            if right_count > (end - start + 1) // 2:\n",
        "                return right_major\n",
        "\n",
        "\n",
        "            return -1  # No majority in this range\n",
        "\n",
        "\n",
        "        candidate = majority_rec(0, len(arr) - 1)\n",
        "        if candidate == -1:\n",
        "            return -1\n",
        "\n",
        "\n",
        "        # Verify the count\n",
        "        count = sum(1 for x in arr if x == candidate)\n",
        "        return candidate if count > len(arr) // 2 else -1\n",
        "\n",
        "\n",
        "    def verify_majority(self, arr: List[int], result: int) -> Tuple[bool, str]:\n",
        "        \"\"\"\n",
        "        Verify that the majority element is correct.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            arr (List[int]): Input array\n",
        "            result (int): Reported majority element or -1\n",
        "\n",
        "\n",
        "        Returns:\n",
        "            Tuple[bool, str]: (is_valid, error_message)\n",
        "        \"\"\"\n",
        "        if not arr:\n",
        "            return result == -1, \"Valid for empty array\" if result == -1 else \"Invalid for empty array\"\n",
        "\n",
        "\n",
        "        from collections import Counter\n",
        "        counts = Counter(arr)\n",
        "        n = len(arr)\n",
        "        threshold = n // 2\n",
        "\n",
        "\n",
        "        if result == -1:\n",
        "            # Check if no element exceeds threshold\n",
        "            if all(count <= threshold for count in counts.values()):\n",
        "                return True, \"Valid: No majority element\"\n",
        "            else:\n",
        "                max_elem = max(counts, key=counts.get)\n",
        "                return False, f\"Invalid: {max_elem} appears {counts[max_elem]} > {threshold} times\"\n",
        "        else:\n",
        "            # Check if result appears > n/2 times\n",
        "            if result not in counts:\n",
        "                return False, f\"Result {result} not in array\"\n",
        "            if counts[result] <= threshold:\n",
        "                return False, f\"Result {result} appears {counts[result]} <= {threshold} times\"\n",
        "\n",
        "\n",
        "            # Check if it's indeed the majority\n",
        "            if counts[result] > threshold:\n",
        "                return True, f\"Valid: {result} appears {counts[result]} > {threshold} times\"\n",
        "            return False, \"Invalid majority\"\n",
        "\n",
        "\n",
        "def parse_input_file(file_path: str) -> Tuple[int, int, List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Parse input file to extract k, n, and k arrays each of size n.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "\n",
        "        if len(lines) < 1:\n",
        "            raise ValueError(\"Input file is empty\")\n",
        "\n",
        "\n",
        "        # Parse k and n\n",
        "        first_line = list(map(int, lines[0].split()))\n",
        "        if len(first_line) != 2:\n",
        "            raise ValueError(\"First line must contain exactly two integers: k and n\")\n",
        "        k, n = first_line\n",
        "\n",
        "\n",
        "        if len(lines) != k + 1:\n",
        "            raise ValueError(f\"Expected {k + 1} lines, found {len(lines)}\")\n",
        "\n",
        "\n",
        "        # Parse k arrays\n",
        "        arrays = []\n",
        "        for i in range(1, k + 1):\n",
        "            arr = list(map(int, lines[i].split()))\n",
        "            if len(arr) != n:\n",
        "                raise ValueError(f\"Array {i} length {len(arr)} doesn't match n={n}\")\n",
        "            arrays.append(arr)\n",
        "\n",
        "\n",
        "        return k, n, arrays\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Input file '{file_path}' not found\")\n",
        "    except ValueError as e:\n",
        "        raise ValueError(f\"Input parsing error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def write_output_file(output_path: str, results: List[int]) -> None:\n",
        "    \"\"\"\n",
        "    Write majority elements to output file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(' '.join(map(str, results)) + '\\n')\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error writing to output file: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def solve_majority_problem(input_file_path: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Solve the majority element problem for a given input file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse input\n",
        "        k, n, arrays = parse_input_file(input_file_path)\n",
        "\n",
        "\n",
        "        print(f\"Parsed input: k={k}, n={n}, {k} arrays\")\n",
        "\n",
        "\n",
        "        # Initialize finder\n",
        "        finder = MajorityFinder()\n",
        "\n",
        "\n",
        "        # Find majority for each array\n",
        "        results = []\n",
        "        for i, arr in enumerate(arrays, 1):\n",
        "            major = finder.find_majority(arr)\n",
        "            results.append(major)\n",
        "\n",
        "\n",
        "            # Verify\n",
        "            is_valid, msg = finder.verify_majority(arr, major)\n",
        "            if not is_valid:\n",
        "                raise ValueError(f\"Invalid result for array {i}: {msg}\")\n",
        "\n",
        "\n",
        "            print(f\"Array {i}: majority {major} - {msg}\")\n",
        "\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error solving problem: {str(e)}\")\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the majority element problem solver.\n",
        "    \"\"\"\n",
        "    # Configuration\n",
        "    input_file = \"rosalind_maj.txt\"  # Change this to your input file name\n",
        "    output_file = \"output_maj.txt\"\n",
        "\n",
        "\n",
        "    try:\n",
        "        print(\"Solving Majority Element Problem...\")\n",
        "\n",
        "\n",
        "        # Solve the problem\n",
        "        results = solve_majority_problem(input_file)\n",
        "\n",
        "\n",
        "        # Display results\n",
        "        print(f\"\\nResult:\")\n",
        "        print(f\"Majority elements: {' '.join(map(str, results))}\")\n",
        "\n",
        "\n",
        "        # Write to output file\n",
        "        write_output_file(output_file, results)\n",
        "        print(f\"Result written to: {output_file}\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{input_file}' not found.\")\n",
        "        print(\"Please make sure the file exists in the current directory.\")\n",
        "\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def test_majority_finder():\n",
        "    \"\"\"Test the majority finder with sample and edge cases.\"\"\"\n",
        "    print(\"=== Testing Majority Finder ===\")\n",
        "\n",
        "\n",
        "    test_cases = [\n",
        "        # Sample dataset arrays\n",
        "        [5, 5, 5, 5, 5, 5, 5, 5],                # 5 is majority\n",
        "        [8, 7, 7, 7, 1, 7, 3, 7],                # 7 is majority (5 times > 4)\n",
        "        [7, 1, 6, 5, 10, 100, 1000, 1],          # No majority\n",
        "        [5, 1, 6, 7, 1, 1, 10, 1],               # 1 appears 4 times == 4, but need >4? Wait, n=8, >4\n",
        "        # Note: for n=8, >4 means at least 5\n",
        "        # In sample, last one has 1 appearing 4 times, so -1\n",
        "        # Additional tests\n",
        "        [],                                      # Empty\n",
        "        [1],                                     # Single element\n",
        "        [1, 2],                                  # No majority\n",
        "        [1, 1, 2],                               # 1 appears 2 > 1.5\n",
        "        [1, 2, 2, 3],                            # No majority\n",
        "        [2, 2, 2, 2],                            # 2 is majority\n",
        "    ]\n",
        "\n",
        "\n",
        "    expected = [5, 7, -1, -1, -1, 1, -1, 1, -1, 2]\n",
        "\n",
        "\n",
        "    finder = MajorityFinder()\n",
        "\n",
        "\n",
        "    for i, arr in enumerate(test_cases, 1):\n",
        "        print(f\"\\nTest {i}: {arr}\")\n",
        "\n",
        "\n",
        "        result = finder.find_majority(arr)\n",
        "        print(f\"Result: {result}\")\n",
        "\n",
        "\n",
        "        is_valid, msg = finder.verify_majority(arr, result)\n",
        "        print(f\"Valid: {'✓' if is_valid else '✗'} - {msg}\")\n",
        "\n",
        "\n",
        "        if i <= len(expected):\n",
        "            exp = expected[i-1]\n",
        "            print(f\"Matches expected {exp}: {'✓' if result == exp else '✗'}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run tests\n",
        "    test_majority_finder()\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "\n",
        "    # Run main function\n",
        "    print(\"Running main function...\")\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "vDxHSagk9IuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}